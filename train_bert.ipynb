{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d29afd-314e-4f60-a94c-c9e1a2bfe630",
   "metadata": {},
   "source": [
    "# Import libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768cf98-f2a2-4dc6-b1c9-72af9433910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import BertJapaneseTokenizer, BertTokenizer\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcfd072-34fa-4757-867b-345fbb72a118",
   "metadata": {},
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7e21a-2d45-4c57-a60e-6067c96d6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"cl-tohoku/bert-base-japanese\"\n",
    "\n",
    "MAX_SEQ_LEN = 512\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "DATA_DIR = \"train\"\n",
    "MODEL_DIR = \"models\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f32591-f102-47c4-aea6-c009d1886665",
   "metadata": {},
   "source": [
    "# Randomize seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcdeff9-7cd3-4a78-bc05-1d1d8cd8c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30881bb-f3f3-4f56-9046-fd9b324053e9",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab1a3c-5678-4af6-a8c9-e7363d500687",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.read_csv(f\"{DATA_DIR}/train_positive.csv\", lineterminator=\"\\n\").dropna()\n",
    "negative_df = pd.read_csv(f\"{DATA_DIR}/train_negative.csv\", lineterminator=\"\\n\").dropna()\n",
    "\n",
    "positive_df[\"Label\"] = 1\n",
    "negative_df[\"Label\"] = 0\n",
    "\n",
    "print(len(positive_df))\n",
    "print(len(negative_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba598b-d2e5-41cb-bb85-bb7b341d2bb8",
   "metadata": {},
   "source": [
    "# Concat train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf410c-a672-483a-8a1f-9dc16ae35266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([positive_df, negative_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6bd74e-4acc-45e7-9f90-a7157e04d6e4",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc449286-a81a-45dd-8874-1d66ebed05cb",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a29854-8142-4b50-a0a5-edecda292d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[\"Text\"].values, \n",
    "    add_special_tokens = True, \n",
    "    return_attention_mask = True, \n",
    "    padding = \"max_length\", \n",
    "    max_length = MAX_SEQ_LEN, \n",
    "    return_tensors = \"pt\",\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc64f1-f9f2-4042-8f7e-f29be90522ff",
   "metadata": {},
   "source": [
    "## Make train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa7e8e-4951-44a0-8d07-e5f6630963d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "\n",
    "input_ids = encoded_data_train[\"input_ids\"]\n",
    "attention_masks = encoded_data_train[\"attention_mask\"]\n",
    "labels = torch.tensor(df[\"Label\"].values)\n",
    "\n",
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,           # The training samples.\n",
    "            shuffle=True,            # Select batches randomly\n",
    "            batch_size = BATCH_SIZE, # Trains with this batch size.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e60de2-1971-41f1-aa4f-60012c1c03b6",
   "metadata": {},
   "source": [
    "## Train main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea96e8a-9b4a-4194-8640-46ba2ca1d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels = 2,\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-5, \n",
    "    eps = 1e-8\n",
    ")\n",
    "\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 50, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc = \"Epoch {:1d}\".format(epoch), leave = False, disable = False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(DEVICE) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[2],\n",
    "        }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"training_loss\": \"{:.3f}\".format(loss.item()/len(batch))})\n",
    "        del loss\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    loss_train_avg = loss_train_total/len(train_dataloader)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"{MODEL_DIR}/model_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc226af1-5d12-49c6-b49d-65a42f8453a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
